{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, StackingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, cohen_kappa_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identified</th>\n",
       "      <th>4000</th>\n",
       "      <th>3999</th>\n",
       "      <th>3998</th>\n",
       "      <th>3997</th>\n",
       "      <th>3996</th>\n",
       "      <th>3995</th>\n",
       "      <th>3994</th>\n",
       "      <th>3993</th>\n",
       "      <th>3992</th>\n",
       "      <th>...</th>\n",
       "      <th>459</th>\n",
       "      <th>458</th>\n",
       "      <th>457</th>\n",
       "      <th>456</th>\n",
       "      <th>455</th>\n",
       "      <th>454</th>\n",
       "      <th>453</th>\n",
       "      <th>452</th>\n",
       "      <th>451</th>\n",
       "      <th>450</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDPE</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>...</td>\n",
       "      <td>96.83</td>\n",
       "      <td>96.84</td>\n",
       "      <td>96.85</td>\n",
       "      <td>96.83</td>\n",
       "      <td>96.77</td>\n",
       "      <td>96.66</td>\n",
       "      <td>96.54</td>\n",
       "      <td>96.46</td>\n",
       "      <td>96.43</td>\n",
       "      <td>96.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>...</td>\n",
       "      <td>93.80</td>\n",
       "      <td>93.77</td>\n",
       "      <td>93.86</td>\n",
       "      <td>94.01</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.08</td>\n",
       "      <td>94.12</td>\n",
       "      <td>94.23</td>\n",
       "      <td>94.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PP</td>\n",
       "      <td>99.23</td>\n",
       "      <td>99.22</td>\n",
       "      <td>99.22</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.20</td>\n",
       "      <td>99.20</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.21</td>\n",
       "      <td>...</td>\n",
       "      <td>93.98</td>\n",
       "      <td>94.00</td>\n",
       "      <td>94.05</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.14</td>\n",
       "      <td>94.23</td>\n",
       "      <td>94.38</td>\n",
       "      <td>94.57</td>\n",
       "      <td>94.75</td>\n",
       "      <td>94.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mixture</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>...</td>\n",
       "      <td>96.41</td>\n",
       "      <td>96.45</td>\n",
       "      <td>96.50</td>\n",
       "      <td>96.55</td>\n",
       "      <td>96.62</td>\n",
       "      <td>96.68</td>\n",
       "      <td>96.74</td>\n",
       "      <td>96.77</td>\n",
       "      <td>96.78</td>\n",
       "      <td>96.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDPE</td>\n",
       "      <td>99.55</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>...</td>\n",
       "      <td>95.28</td>\n",
       "      <td>95.22</td>\n",
       "      <td>95.23</td>\n",
       "      <td>95.30</td>\n",
       "      <td>95.38</td>\n",
       "      <td>95.41</td>\n",
       "      <td>95.35</td>\n",
       "      <td>95.24</td>\n",
       "      <td>95.21</td>\n",
       "      <td>95.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>PP</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.74</td>\n",
       "      <td>99.74</td>\n",
       "      <td>99.73</td>\n",
       "      <td>...</td>\n",
       "      <td>98.58</td>\n",
       "      <td>98.58</td>\n",
       "      <td>98.65</td>\n",
       "      <td>98.76</td>\n",
       "      <td>98.85</td>\n",
       "      <td>98.88</td>\n",
       "      <td>98.87</td>\n",
       "      <td>98.87</td>\n",
       "      <td>98.92</td>\n",
       "      <td>98.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>Mixture</td>\n",
       "      <td>99.62</td>\n",
       "      <td>99.62</td>\n",
       "      <td>99.62</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>...</td>\n",
       "      <td>97.02</td>\n",
       "      <td>97.08</td>\n",
       "      <td>97.16</td>\n",
       "      <td>97.23</td>\n",
       "      <td>97.27</td>\n",
       "      <td>97.30</td>\n",
       "      <td>97.32</td>\n",
       "      <td>97.34</td>\n",
       "      <td>97.39</td>\n",
       "      <td>97.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Mixture</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.93</td>\n",
       "      <td>...</td>\n",
       "      <td>96.94</td>\n",
       "      <td>97.01</td>\n",
       "      <td>97.05</td>\n",
       "      <td>97.07</td>\n",
       "      <td>97.08</td>\n",
       "      <td>97.06</td>\n",
       "      <td>97.01</td>\n",
       "      <td>96.97</td>\n",
       "      <td>96.97</td>\n",
       "      <td>97.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>HDPE</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.57</td>\n",
       "      <td>...</td>\n",
       "      <td>94.32</td>\n",
       "      <td>94.38</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.51</td>\n",
       "      <td>94.52</td>\n",
       "      <td>94.52</td>\n",
       "      <td>94.53</td>\n",
       "      <td>94.51</td>\n",
       "      <td>94.42</td>\n",
       "      <td>94.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>HDPE</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>98.99</td>\n",
       "      <td>98.98</td>\n",
       "      <td>98.99</td>\n",
       "      <td>98.98</td>\n",
       "      <td>98.99</td>\n",
       "      <td>98.99</td>\n",
       "      <td>99.00</td>\n",
       "      <td>...</td>\n",
       "      <td>95.97</td>\n",
       "      <td>96.02</td>\n",
       "      <td>96.05</td>\n",
       "      <td>96.05</td>\n",
       "      <td>96.02</td>\n",
       "      <td>95.98</td>\n",
       "      <td>95.90</td>\n",
       "      <td>95.80</td>\n",
       "      <td>95.75</td>\n",
       "      <td>95.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 3552 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    identified   4000   3999   3998   3997   3996   3995   3994   3993   3992  \\\n",
       "0         HDPE  99.51  99.51  99.51  99.51  99.51  99.50  99.50  99.50  99.50   \n",
       "1           PP  99.03  99.03  99.03  99.03  99.02  99.02  99.02  99.02  99.02   \n",
       "2           PP  99.23  99.22  99.22  99.21  99.21  99.20  99.20  99.21  99.21   \n",
       "3      Mixture  99.50  99.50  99.50  99.50  99.51  99.51  99.51  99.51  99.51   \n",
       "4         HDPE  99.55  99.56  99.56  99.57  99.57  99.57  99.56  99.56  99.56   \n",
       "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "795         PP  99.75  99.75  99.75  99.75  99.75  99.75  99.74  99.74  99.73   \n",
       "796    Mixture  99.62  99.62  99.62  99.63  99.63  99.63  99.63  99.63  99.63   \n",
       "797    Mixture  99.92  99.92  99.92  99.92  99.92  99.92  99.92  99.93  99.93   \n",
       "798       HDPE  99.58  99.58  99.58  99.58  99.58  99.58  99.58  99.58  99.57   \n",
       "799       HDPE  99.00  99.00  98.99  98.98  98.99  98.98  98.99  98.99  99.00   \n",
       "\n",
       "     ...    459    458    457    456    455    454    453    452    451    450  \n",
       "0    ...  96.83  96.84  96.85  96.83  96.77  96.66  96.54  96.46  96.43  96.44  \n",
       "1    ...  93.80  93.77  93.86  94.01  94.09  94.09  94.08  94.12  94.23  94.36  \n",
       "2    ...  93.98  94.00  94.05  94.09  94.14  94.23  94.38  94.57  94.75  94.87  \n",
       "3    ...  96.41  96.45  96.50  96.55  96.62  96.68  96.74  96.77  96.78  96.80  \n",
       "4    ...  95.28  95.22  95.23  95.30  95.38  95.41  95.35  95.24  95.21  95.07  \n",
       "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "795  ...  98.58  98.58  98.65  98.76  98.85  98.88  98.87  98.87  98.92  98.98  \n",
       "796  ...  97.02  97.08  97.16  97.23  97.27  97.30  97.32  97.34  97.39  97.47  \n",
       "797  ...  96.94  97.01  97.05  97.07  97.08  97.06  97.01  96.97  96.97  97.02  \n",
       "798  ...  94.32  94.38  94.46  94.51  94.52  94.52  94.53  94.51  94.42  94.31  \n",
       "799  ...  95.97  96.02  96.05  96.05  96.02  95.98  95.90  95.80  95.75  95.75  \n",
       "\n",
       "[800 rows x 3552 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jung = pd.read_csv(\"/home/kumail/Energy_AI/Micro Palstic/Dataset/Jung et Dataset.csv\")\n",
    "Jung = Jung.drop(columns=['Turtle_piece.scan'])\n",
    "Jung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "identified\n",
       "HDPE       438\n",
       "PP         272\n",
       "Mixture     39\n",
       "LDPE        37\n",
       "PS           7\n",
       "Unknown      4\n",
       "Nylon        1\n",
       "PVC          1\n",
       "PETE         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jung_counts = Jung['identified'].value_counts()\n",
    "Jung_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2977/3446870954.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Jung['identified'] = Jung['identified'].replace('PS', 'Unknown')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "identified\n",
       "HDPE       438\n",
       "PP         272\n",
       "Mixture     39\n",
       "LDPE        37\n",
       "Unknown     11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_to_remove = ['Nylon', 'PVC', 'PETE']\n",
    "Jung = Jung[~Jung['identified'].isin(values_to_remove)]\n",
    "Jung['identified'] = Jung['identified'].replace('PS', 'Unknown')\n",
    "Jung_counts = Jung['identified'].value_counts()\n",
    "Jung_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2977/1603336163.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Jung['identified_encoded'] = label_encoder.fit_transform(Jung['identified'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4000</th>\n",
       "      <th>3999</th>\n",
       "      <th>3998</th>\n",
       "      <th>3997</th>\n",
       "      <th>3996</th>\n",
       "      <th>3995</th>\n",
       "      <th>3994</th>\n",
       "      <th>3993</th>\n",
       "      <th>3992</th>\n",
       "      <th>3991</th>\n",
       "      <th>...</th>\n",
       "      <th>458</th>\n",
       "      <th>457</th>\n",
       "      <th>456</th>\n",
       "      <th>455</th>\n",
       "      <th>454</th>\n",
       "      <th>453</th>\n",
       "      <th>452</th>\n",
       "      <th>451</th>\n",
       "      <th>450</th>\n",
       "      <th>identified_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.51</td>\n",
       "      <td>...</td>\n",
       "      <td>96.84</td>\n",
       "      <td>96.85</td>\n",
       "      <td>96.83</td>\n",
       "      <td>96.77</td>\n",
       "      <td>96.66</td>\n",
       "      <td>96.54</td>\n",
       "      <td>96.46</td>\n",
       "      <td>96.43</td>\n",
       "      <td>96.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.03</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>...</td>\n",
       "      <td>93.77</td>\n",
       "      <td>93.86</td>\n",
       "      <td>94.01</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.08</td>\n",
       "      <td>94.12</td>\n",
       "      <td>94.23</td>\n",
       "      <td>94.36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.23</td>\n",
       "      <td>99.22</td>\n",
       "      <td>99.22</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.20</td>\n",
       "      <td>99.20</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.22</td>\n",
       "      <td>...</td>\n",
       "      <td>94.00</td>\n",
       "      <td>94.05</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.14</td>\n",
       "      <td>94.23</td>\n",
       "      <td>94.38</td>\n",
       "      <td>94.57</td>\n",
       "      <td>94.75</td>\n",
       "      <td>94.87</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>...</td>\n",
       "      <td>96.45</td>\n",
       "      <td>96.50</td>\n",
       "      <td>96.55</td>\n",
       "      <td>96.62</td>\n",
       "      <td>96.68</td>\n",
       "      <td>96.74</td>\n",
       "      <td>96.77</td>\n",
       "      <td>96.78</td>\n",
       "      <td>96.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.55</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>...</td>\n",
       "      <td>95.22</td>\n",
       "      <td>95.23</td>\n",
       "      <td>95.30</td>\n",
       "      <td>95.38</td>\n",
       "      <td>95.41</td>\n",
       "      <td>95.35</td>\n",
       "      <td>95.24</td>\n",
       "      <td>95.21</td>\n",
       "      <td>95.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.74</td>\n",
       "      <td>99.74</td>\n",
       "      <td>99.73</td>\n",
       "      <td>99.73</td>\n",
       "      <td>...</td>\n",
       "      <td>98.58</td>\n",
       "      <td>98.65</td>\n",
       "      <td>98.76</td>\n",
       "      <td>98.85</td>\n",
       "      <td>98.88</td>\n",
       "      <td>98.87</td>\n",
       "      <td>98.87</td>\n",
       "      <td>98.92</td>\n",
       "      <td>98.98</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>99.62</td>\n",
       "      <td>99.62</td>\n",
       "      <td>99.62</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.64</td>\n",
       "      <td>...</td>\n",
       "      <td>97.08</td>\n",
       "      <td>97.16</td>\n",
       "      <td>97.23</td>\n",
       "      <td>97.27</td>\n",
       "      <td>97.30</td>\n",
       "      <td>97.32</td>\n",
       "      <td>97.34</td>\n",
       "      <td>97.39</td>\n",
       "      <td>97.47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.93</td>\n",
       "      <td>...</td>\n",
       "      <td>97.01</td>\n",
       "      <td>97.05</td>\n",
       "      <td>97.07</td>\n",
       "      <td>97.08</td>\n",
       "      <td>97.06</td>\n",
       "      <td>97.01</td>\n",
       "      <td>96.97</td>\n",
       "      <td>96.97</td>\n",
       "      <td>97.02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.57</td>\n",
       "      <td>...</td>\n",
       "      <td>94.38</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.51</td>\n",
       "      <td>94.52</td>\n",
       "      <td>94.52</td>\n",
       "      <td>94.53</td>\n",
       "      <td>94.51</td>\n",
       "      <td>94.42</td>\n",
       "      <td>94.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>98.99</td>\n",
       "      <td>98.98</td>\n",
       "      <td>98.99</td>\n",
       "      <td>98.98</td>\n",
       "      <td>98.99</td>\n",
       "      <td>98.99</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>...</td>\n",
       "      <td>96.02</td>\n",
       "      <td>96.05</td>\n",
       "      <td>96.05</td>\n",
       "      <td>96.02</td>\n",
       "      <td>95.98</td>\n",
       "      <td>95.90</td>\n",
       "      <td>95.80</td>\n",
       "      <td>95.75</td>\n",
       "      <td>95.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>797 rows × 3552 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      4000   3999   3998   3997   3996   3995   3994   3993   3992   3991  \\\n",
       "0    99.51  99.51  99.51  99.51  99.51  99.50  99.50  99.50  99.50  99.51   \n",
       "1    99.03  99.03  99.03  99.03  99.02  99.02  99.02  99.02  99.02  99.02   \n",
       "2    99.23  99.22  99.22  99.21  99.21  99.20  99.20  99.21  99.21  99.22   \n",
       "3    99.50  99.50  99.50  99.50  99.51  99.51  99.51  99.51  99.51  99.51   \n",
       "4    99.55  99.56  99.56  99.57  99.57  99.57  99.56  99.56  99.56  99.56   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "795  99.75  99.75  99.75  99.75  99.75  99.75  99.74  99.74  99.73  99.73   \n",
       "796  99.62  99.62  99.62  99.63  99.63  99.63  99.63  99.63  99.63  99.64   \n",
       "797  99.92  99.92  99.92  99.92  99.92  99.92  99.92  99.93  99.93  99.93   \n",
       "798  99.58  99.58  99.58  99.58  99.58  99.58  99.58  99.58  99.57  99.57   \n",
       "799  99.00  99.00  98.99  98.98  98.99  98.98  98.99  98.99  99.00  99.00   \n",
       "\n",
       "     ...    458    457    456    455    454    453    452    451    450  \\\n",
       "0    ...  96.84  96.85  96.83  96.77  96.66  96.54  96.46  96.43  96.44   \n",
       "1    ...  93.77  93.86  94.01  94.09  94.09  94.08  94.12  94.23  94.36   \n",
       "2    ...  94.00  94.05  94.09  94.14  94.23  94.38  94.57  94.75  94.87   \n",
       "3    ...  96.45  96.50  96.55  96.62  96.68  96.74  96.77  96.78  96.80   \n",
       "4    ...  95.22  95.23  95.30  95.38  95.41  95.35  95.24  95.21  95.07   \n",
       "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "795  ...  98.58  98.65  98.76  98.85  98.88  98.87  98.87  98.92  98.98   \n",
       "796  ...  97.08  97.16  97.23  97.27  97.30  97.32  97.34  97.39  97.47   \n",
       "797  ...  97.01  97.05  97.07  97.08  97.06  97.01  96.97  96.97  97.02   \n",
       "798  ...  94.38  94.46  94.51  94.52  94.52  94.53  94.51  94.42  94.31   \n",
       "799  ...  96.02  96.05  96.05  96.02  95.98  95.90  95.80  95.75  95.75   \n",
       "\n",
       "     identified_encoded  \n",
       "0                     0  \n",
       "1                     3  \n",
       "2                     3  \n",
       "3                     2  \n",
       "4                     0  \n",
       "..                  ...  \n",
       "795                   3  \n",
       "796                   2  \n",
       "797                   2  \n",
       "798                   0  \n",
       "799                   0  \n",
       "\n",
       "[797 rows x 3552 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Interpretation' column\n",
    "Jung['identified_encoded'] = label_encoder.fit_transform(Jung['identified'])\n",
    "Jung = Jung.drop(columns=['identified'])\n",
    "Jung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Jung.drop(columns=['identified_encoded'])\n",
    "Y = Jung['identified_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(797, 9)\n",
      "Explained Variance Ratio of each principal component:\n",
      "[0.49899195 0.282692   0.10894243 0.05868484 0.02262672 0.00786886\n",
      " 0.00572934 0.00241824 0.00206183]\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer(norm='max')\n",
    "data_scaled = normalizer.fit_transform(X)\n",
    "pca = PCA(n_components=9)\n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "print(data_pca.shape)\n",
    "\n",
    "# Check how much variance each component explains\n",
    "print(\"Explained Variance Ratio of each principal component:\")\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 637\n",
      "Test set size: 160\n",
      "After preprocessing Training set size: (637, 9)\n",
      "After preprocessing Test set size: (160, 9)\n"
     ]
    }
   ],
   "source": [
    "def split_and_scale_data(X, Y, test_size=0.2, random_state=42):\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    \n",
    "    print(f\"Training set size: {X_train.shape[0]}\")\n",
    "    print(f\"Test set size: {X_test.shape[0]}\")\n",
    "    print(f\"After preprocessing Training set size: {X_train.shape}\")\n",
    "    print(f\"After preprocessing Test set size: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, Y_train,  Y_test\n",
    "X_train_scaled,  X_test_scaled, Y_train,  Y_test = split_and_scale_data(data_pca, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = ExtraTreesClassifier(\n",
    "    n_estimators=500, max_depth=35, min_samples_split=7, min_samples_leaf=1, max_features='sqrt', random_state=42\n",
    ")\n",
    "clf2 = DecisionTreeClassifier(\n",
    "    max_depth=15, min_samples_split=14, min_samples_leaf=5, criterion='entropy', random_state=42\n",
    ")\n",
    "clf3 = SVC(\n",
    "    C=42.26721781758463, kernel='rbf', gamma='auto', probability=True, random_state=42\n",
    ")\n",
    "clf4 = xgb.XGBClassifier(\n",
    "    n_estimators=900, max_depth=9, learning_rate=0.21577743453773293,\n",
    "    subsample=0.7134596184717141, colsample_bytree=0.8926104458835206, \n",
    "    gamma=0.06934334083160099, reg_alpha=0.6613878247418032, reg_lambda=0.26856628937579974,\n",
    "    random_state=42, use_label_encoder=False, eval_metric='mlogloss'\n",
    ")\n",
    "clf5 = lgb.LGBMClassifier(\n",
    "    n_estimators=700, max_depth=7, learning_rate=0.0855852309100438, num_leaves=138, \n",
    "    min_child_samples=62, subsample=0.9673844529941501, colsample_bytree=0.7343207921501621,\n",
    "    reg_alpha=0.2369598754789148, reg_lambda=0.5701128436794478, random_state=42\n",
    ")\n",
    "clf6 = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=30, min_samples_split=4, min_samples_leaf=1, \n",
    "    max_features='log2', bootstrap=True, random_state=42\n",
    ")\n",
    "clf9 = GradientBoostingClassifier(\n",
    "    n_estimators=200, learning_rate=0.17387802436141037, max_depth=10, \n",
    "    min_samples_split=12, min_samples_leaf=6, subsample=0.547399138004244, \n",
    "    max_features='sqrt', loss='log_loss', random_state=42\n",
    ")\n",
    "clf10 = AdaBoostClassifier(\n",
    "    n_estimators=500, learning_rate=0.6574797025901895, algorithm='SAMME.R', random_state=42\n",
    ")\n",
    "clf11 = cb.CatBoostClassifier(\n",
    "    n_estimators=600, learning_rate=0.07472477144852825, max_depth=10, min_data_in_leaf=9, \n",
    "    l2_leaf_reg=7.404283846568703, border_count=192, silent=True, random_state=42\n",
    ")\n",
    "clf12 = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 128), activation='relu', solver='lbfgs', \n",
    "    alpha=0.09632315546143085, learning_rate='invscaling', max_iter=1800, random_state=42\n",
    ")\n",
    "\n",
    "# Stacking ensemble\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('et', clf1), ('dt', clf2), ('svc', clf3), ('xgb', clf4), \n",
    "        ('lgbm', clf5), ('rf', clf6), ('gb', clf9), \n",
    "        ('ab', clf10), ('catboost', clf11), ('mlp', clf12)\n",
    "    ],\n",
    "    final_estimator=lgb.LGBMClassifier(n_estimators=700, max_depth=7, learning_rate=0.0855852309100438, num_leaves=138, \n",
    "    min_child_samples=62, subsample=0.9673844529941501, colsample_bytree=0.7343207921501621,\n",
    "    reg_alpha=0.2369598754789148, reg_lambda=0.5701128436794478,random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('model', stacking_clf)  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "stacking_clf.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = stacking_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.9313\n",
      "Stacking Classifier F1 Score: 0.9292\n",
      "Stacking Classifier Precision: 0.9291\n",
      "Stacking Classifier Recall: 0.9313\n",
      "Stacking Classifier Kappa Score: 0.8791\n"
     ]
    }
   ],
   "source": [
    "y_pred = stacking_clf.predict(X_test_scaled)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "f1 = f1_score(Y_test, y_pred, average='weighted')  \n",
    "precision = precision_score(Y_test, y_pred, average='weighted')\n",
    "recall = recall_score(Y_test, y_pred, average='weighted')\n",
    "kappa = cohen_kappa_score(Y_test, y_pred)\n",
    "\n",
    "# Print Results\n",
    "print(f\"Stacking Classifier Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Stacking Classifier F1 Score: {f1:.4f}\")\n",
    "print(f\"Stacking Classifier Precision: {precision:.4f}\")\n",
    "print(f\"Stacking Classifier Recall: {recall:.4f}\")\n",
    "print(f\"Stacking Classifier Kappa Score: {kappa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(stacking_clf, 'Jung_PCA_9_80_20_split_stacking_clf_model.pkl')\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/kumail/Energy_AI/Micro Palstic/Model/Jung_PCA_9_80_20_split_stacking_clf_model.pkl\"\n",
    "stacking_clf = joblib.load(model_path)\n",
    "y_pred = stacking_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        91\n",
      "           1       0.50      0.43      0.46         7\n",
      "           2       1.00      0.80      0.89        10\n",
      "           3       0.98      1.00      0.99        49\n",
      "           4       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.93       160\n",
      "   macro avg       0.82      0.77      0.79       160\n",
      "weighted avg       0.93      0.93      0.93       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix_normalized, annot=np.round(conf_matrix_normalized, 2), fmt='.2f', cmap='viridis', \n",
    "            xticklabels=sorted(set(Y_test)), \n",
    "            yticklabels=sorted(set(Y_test)))\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Predicted Classes')\n",
    "plt.ylabel('Actual Classes')\n",
    "plt.title('Normalized Confusion Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.9500\n",
      "  F1 Score: 0.9463\n",
      "  Precision: 0.9517\n",
      "  Recall: 0.9500\n",
      "  Cohen's Kappa: 0.9125\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n",
      "  Accuracy: 0.9125\n",
      "  F1 Score: 0.9025\n",
      "  Precision: 0.9159\n",
      "  Recall: 0.9125\n",
      "  Cohen's Kappa: 0.8451\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3:\n",
      "  Accuracy: 0.9125\n",
      "  F1 Score: 0.9011\n",
      "  Precision: 0.9042\n",
      "  Recall: 0.9125\n",
      "  Cohen's Kappa: 0.8419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4:\n",
      "  Accuracy: 0.8750\n",
      "  F1 Score: 0.8686\n",
      "  Precision: 0.8643\n",
      "  Recall: 0.8750\n",
      "  Cohen's Kappa: 0.7803\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5:\n",
      "  Accuracy: 0.9500\n",
      "  F1 Score: 0.9478\n",
      "  Precision: 0.9475\n",
      "  Recall: 0.9500\n",
      "  Cohen's Kappa: 0.9122\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6:\n",
      "  Accuracy: 0.9625\n",
      "  F1 Score: 0.9527\n",
      "  Precision: 0.9524\n",
      "  Recall: 0.9625\n",
      "  Cohen's Kappa: 0.9329\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7:\n",
      "  Accuracy: 0.9500\n",
      "  F1 Score: 0.9461\n",
      "  Precision: 0.9511\n",
      "  Recall: 0.9500\n",
      "  Cohen's Kappa: 0.9117\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8:\n",
      "  Accuracy: 0.9367\n",
      "  F1 Score: 0.9277\n",
      "  Precision: 0.9219\n",
      "  Recall: 0.9367\n",
      "  Cohen's Kappa: 0.8868\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9:\n",
      "  Accuracy: 0.9620\n",
      "  F1 Score: 0.9437\n",
      "  Precision: 0.9265\n",
      "  Recall: 0.9620\n",
      "  Cohen's Kappa: 0.9315\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10:\n",
      "  Accuracy: 0.9747\n",
      "  F1 Score: 0.9743\n",
      "  Precision: 0.9781\n",
      "  Recall: 0.9747\n",
      "  Cohen's Kappa: 0.9558\n",
      "\n",
      "Overall Results:\n",
      "Mean Accuracy: 0.9386, Std Dev: 0.0287\n",
      "Mean F1 Score: 0.9311, Std Dev: 0.0298\n",
      "Mean Precision: 0.9314, Std Dev: 0.0305\n",
      "Mean Recall: 0.9386, Std Dev: 0.0287\n",
      "Mean Cohen's Kappa: 0.8911, Std Dev: 0.0507\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "Y = Y.to_numpy() if isinstance(Y, pd.Series) else Y\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "kappas = []\n",
    "\n",
    "fold_idx = 1\n",
    "for train_idx, test_idx in cv.split(data_pca, Y):\n",
    "    X_train, X_test = data_pca[train_idx], data_pca[test_idx]\n",
    "    y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "    \n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    y_pred = stacking_clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    kappas.append(kappa)\n",
    "\n",
    "    print(f\"Fold {fold_idx}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  Cohen's Kappa: {kappa:.4f}\\n\")\n",
    "    fold_idx += 1\n",
    "\n",
    "print(\"Overall Results:\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f}, Std Dev: {np.std(accuracies):.4f}\")\n",
    "print(f\"Mean F1 Score: {np.mean(f1_scores):.4f}, Std Dev: {np.std(f1_scores):.4f}\")\n",
    "print(f\"Mean Precision: {np.mean(precisions):.4f}, Std Dev: {np.std(precisions):.4f}\")\n",
    "print(f\"Mean Recall: {np.mean(recalls):.4f}, Std Dev: {np.std(recalls):.4f}\")\n",
    "print(f\"Mean Cohen's Kappa: {np.mean(kappas):.4f}, Std Dev: {np.std(kappas):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AliHaq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
