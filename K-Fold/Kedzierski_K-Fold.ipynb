{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, StackingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interpretation</th>\n",
       "      <th>3995.98555</th>\n",
       "      <th>3994.05698</th>\n",
       "      <th>3992.12842</th>\n",
       "      <th>3990.19985</th>\n",
       "      <th>3988.27129</th>\n",
       "      <th>3986.34272</th>\n",
       "      <th>3984.41416</th>\n",
       "      <th>3982.4856</th>\n",
       "      <th>3980.55703</th>\n",
       "      <th>...</th>\n",
       "      <th>617.14062</th>\n",
       "      <th>615.21206</th>\n",
       "      <th>613.2835</th>\n",
       "      <th>611.35493</th>\n",
       "      <th>609.42637</th>\n",
       "      <th>607.4978</th>\n",
       "      <th>605.56924</th>\n",
       "      <th>603.64067</th>\n",
       "      <th>601.71211</th>\n",
       "      <th>599.78354</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal fibre like</td>\n",
       "      <td>-0.040366</td>\n",
       "      <td>-0.135578</td>\n",
       "      <td>-0.221583</td>\n",
       "      <td>-0.178677</td>\n",
       "      <td>-0.062108</td>\n",
       "      <td>0.036045</td>\n",
       "      <td>0.097367</td>\n",
       "      <td>0.140272</td>\n",
       "      <td>0.127931</td>\n",
       "      <td>...</td>\n",
       "      <td>4.588121</td>\n",
       "      <td>4.054936</td>\n",
       "      <td>3.972936</td>\n",
       "      <td>3.872520</td>\n",
       "      <td>3.164385</td>\n",
       "      <td>1.876155</td>\n",
       "      <td>0.578717</td>\n",
       "      <td>-0.018923</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>0.047273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cellulose acetate</td>\n",
       "      <td>-0.024702</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.032219</td>\n",
       "      <td>0.045128</td>\n",
       "      <td>0.046664</td>\n",
       "      <td>0.032280</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>-0.030605</td>\n",
       "      <td>...</td>\n",
       "      <td>2.623865</td>\n",
       "      <td>3.799876</td>\n",
       "      <td>4.907654</td>\n",
       "      <td>5.903986</td>\n",
       "      <td>7.259674</td>\n",
       "      <td>9.334074</td>\n",
       "      <td>11.783750</td>\n",
       "      <td>13.937754</td>\n",
       "      <td>15.418534</td>\n",
       "      <td>16.028218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cellulose acetate</td>\n",
       "      <td>-0.030687</td>\n",
       "      <td>-0.020140</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.072308</td>\n",
       "      <td>0.076775</td>\n",
       "      <td>0.059961</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134722</td>\n",
       "      <td>2.385143</td>\n",
       "      <td>3.963910</td>\n",
       "      <td>5.874066</td>\n",
       "      <td>8.291944</td>\n",
       "      <td>11.536771</td>\n",
       "      <td>14.967054</td>\n",
       "      <td>17.345409</td>\n",
       "      <td>18.209716</td>\n",
       "      <td>17.684628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cellulose acetate</td>\n",
       "      <td>-0.087176</td>\n",
       "      <td>-0.097008</td>\n",
       "      <td>-0.101351</td>\n",
       "      <td>-0.061781</td>\n",
       "      <td>0.021702</td>\n",
       "      <td>0.105184</td>\n",
       "      <td>0.117309</td>\n",
       "      <td>0.058075</td>\n",
       "      <td>-0.012137</td>\n",
       "      <td>...</td>\n",
       "      <td>6.068466</td>\n",
       "      <td>7.771580</td>\n",
       "      <td>8.914805</td>\n",
       "      <td>9.926292</td>\n",
       "      <td>11.322016</td>\n",
       "      <td>13.398389</td>\n",
       "      <td>15.831554</td>\n",
       "      <td>18.264719</td>\n",
       "      <td>20.258756</td>\n",
       "      <td>21.072635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cellulose acetate</td>\n",
       "      <td>-0.037723</td>\n",
       "      <td>-0.025146</td>\n",
       "      <td>-0.026624</td>\n",
       "      <td>-0.028102</td>\n",
       "      <td>-0.010841</td>\n",
       "      <td>0.020474</td>\n",
       "      <td>0.040078</td>\n",
       "      <td>0.024545</td>\n",
       "      <td>-0.005042</td>\n",
       "      <td>...</td>\n",
       "      <td>3.276646</td>\n",
       "      <td>4.012427</td>\n",
       "      <td>4.809110</td>\n",
       "      <td>5.929048</td>\n",
       "      <td>7.569003</td>\n",
       "      <td>9.717262</td>\n",
       "      <td>11.926425</td>\n",
       "      <td>13.838100</td>\n",
       "      <td>15.285976</td>\n",
       "      <td>15.949142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.043015</td>\n",
       "      <td>-0.050403</td>\n",
       "      <td>-0.064003</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.075671</td>\n",
       "      <td>-0.042671</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.082360</td>\n",
       "      <td>0.161963</td>\n",
       "      <td>...</td>\n",
       "      <td>3.505148</td>\n",
       "      <td>3.457383</td>\n",
       "      <td>2.965346</td>\n",
       "      <td>2.445349</td>\n",
       "      <td>2.201856</td>\n",
       "      <td>1.694285</td>\n",
       "      <td>0.708268</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>0.243029</td>\n",
       "      <td>1.180117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.174344</td>\n",
       "      <td>-0.053499</td>\n",
       "      <td>0.067348</td>\n",
       "      <td>0.154828</td>\n",
       "      <td>0.186696</td>\n",
       "      <td>0.207442</td>\n",
       "      <td>0.261555</td>\n",
       "      <td>0.248934</td>\n",
       "      <td>0.136215</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.542803</td>\n",
       "      <td>-7.030846</td>\n",
       "      <td>-10.795946</td>\n",
       "      <td>-12.247627</td>\n",
       "      <td>-12.119956</td>\n",
       "      <td>-12.281461</td>\n",
       "      <td>-12.932345</td>\n",
       "      <td>-13.171705</td>\n",
       "      <td>-12.098646</td>\n",
       "      <td>-9.746533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.011578</td>\n",
       "      <td>0.019579</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.014971</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>-0.005666</td>\n",
       "      <td>-0.002245</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920250</td>\n",
       "      <td>1.039209</td>\n",
       "      <td>1.166181</td>\n",
       "      <td>1.209574</td>\n",
       "      <td>1.239227</td>\n",
       "      <td>1.249415</td>\n",
       "      <td>1.218386</td>\n",
       "      <td>1.236588</td>\n",
       "      <td>1.281125</td>\n",
       "      <td>1.215747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.019956</td>\n",
       "      <td>-0.008994</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.026783</td>\n",
       "      <td>0.016549</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.013787</td>\n",
       "      <td>...</td>\n",
       "      <td>1.465810</td>\n",
       "      <td>1.571245</td>\n",
       "      <td>1.729672</td>\n",
       "      <td>1.806202</td>\n",
       "      <td>1.857681</td>\n",
       "      <td>1.917833</td>\n",
       "      <td>1.903797</td>\n",
       "      <td>1.848330</td>\n",
       "      <td>1.850673</td>\n",
       "      <td>1.860723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.034746</td>\n",
       "      <td>-0.346008</td>\n",
       "      <td>-0.618305</td>\n",
       "      <td>-0.617845</td>\n",
       "      <td>-0.422560</td>\n",
       "      <td>-0.266240</td>\n",
       "      <td>-0.148885</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>0.475477</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.210188</td>\n",
       "      <td>-6.769197</td>\n",
       "      <td>-9.561998</td>\n",
       "      <td>-11.224809</td>\n",
       "      <td>-10.276952</td>\n",
       "      <td>-7.692558</td>\n",
       "      <td>-7.407109</td>\n",
       "      <td>-10.199910</td>\n",
       "      <td>-12.408233</td>\n",
       "      <td>-11.927959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>970 rows × 1763 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Interpretation   3995.98555  3994.05698  3992.12842  3990.19985  \\\n",
       "0    Animal fibre like   -0.040366   -0.135578   -0.221583   -0.178677   \n",
       "1    Cellulose acetate   -0.024702    0.001853    0.017036    0.032219   \n",
       "2    Cellulose acetate   -0.030687   -0.020140    0.014730    0.049600   \n",
       "3    Cellulose acetate   -0.087176   -0.097008   -0.101351   -0.061781   \n",
       "4    Cellulose acetate   -0.037723   -0.025146   -0.026624   -0.028102   \n",
       "..                 ...         ...         ...         ...         ...   \n",
       "965            Unknown   -0.043015   -0.050403   -0.064003   -0.083818   \n",
       "966            Unknown   -0.174344   -0.053499    0.067348    0.154828   \n",
       "967            Unknown    0.011578    0.019579    0.023000    0.014971   \n",
       "968            Unknown   -0.019956   -0.008994    0.009676    0.023529   \n",
       "969            Unknown   -0.034746   -0.346008   -0.618305   -0.617845   \n",
       "\n",
       "     3988.27129  3986.34272  3984.41416  3982.4856  3980.55703  ...  \\\n",
       "0     -0.062108    0.036045    0.097367   0.140272    0.127931  ...   \n",
       "1      0.045128    0.046664    0.032280  -0.000299   -0.030605  ...   \n",
       "2      0.072308    0.076775    0.059961   0.015784   -0.010152  ...   \n",
       "3      0.021702    0.105184    0.117309   0.058075   -0.012137  ...   \n",
       "4     -0.010841    0.020474    0.040078   0.024545   -0.005042  ...   \n",
       "..          ...         ...         ...        ...         ...  ...   \n",
       "965   -0.075671   -0.042671    0.005863   0.082360    0.161963  ...   \n",
       "966    0.186696    0.207442    0.261555   0.248934    0.136215  ...   \n",
       "967    0.001218   -0.005666   -0.002245   0.002321    0.000017  ...   \n",
       "968    0.026783    0.016549    0.003424   0.003788    0.013787  ...   \n",
       "969   -0.422560   -0.266240   -0.148885   0.007436    0.475477  ...   \n",
       "\n",
       "     617.14062  615.21206   613.2835  611.35493  609.42637   607.4978  \\\n",
       "0     4.588121   4.054936   3.972936   3.872520   3.164385   1.876155   \n",
       "1     2.623865   3.799876   4.907654   5.903986   7.259674   9.334074   \n",
       "2     1.134722   2.385143   3.963910   5.874066   8.291944  11.536771   \n",
       "3     6.068466   7.771580   8.914805   9.926292  11.322016  13.398389   \n",
       "4     3.276646   4.012427   4.809110   5.929048   7.569003   9.717262   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "965   3.505148   3.457383   2.965346   2.445349   2.201856   1.694285   \n",
       "966  -2.542803  -7.030846 -10.795946 -12.247627 -12.119956 -12.281461   \n",
       "967   0.920250   1.039209   1.166181   1.209574   1.239227   1.249415   \n",
       "968   1.465810   1.571245   1.729672   1.806202   1.857681   1.917833   \n",
       "969  -4.210188  -6.769197  -9.561998 -11.224809 -10.276952  -7.692558   \n",
       "\n",
       "     605.56924  603.64067  601.71211  599.78354  \n",
       "0     0.578717  -0.018923   0.009571   0.047273  \n",
       "1    11.783750  13.937754  15.418534  16.028218  \n",
       "2    14.967054  17.345409  18.209716  17.684628  \n",
       "3    15.831554  18.264719  20.258756  21.072635  \n",
       "4    11.926425  13.838100  15.285976  15.949142  \n",
       "..         ...        ...        ...        ...  \n",
       "965   0.708268  -0.001245   0.243029   1.180117  \n",
       "966 -12.932345 -13.171705 -12.098646  -9.746533  \n",
       "967   1.218386   1.236588   1.281125   1.215747  \n",
       "968   1.903797   1.848330   1.850673   1.860723  \n",
       "969  -7.407109 -10.199910 -12.408233 -11.927959  \n",
       "\n",
       "[970 rows x 1763 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kedzierski = pd.read_csv(\"/home/kumail/Energy_AI/Micro Palstic/Dataset/Kedzierski et Dataset.csv\")\n",
    "Kedzierski = Kedzierski.drop(columns=['Nom '])\n",
    "Kedzierski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interpretation \n",
       "Poly(ethylene)               228\n",
       "Poly(propylene)              195\n",
       "Poly(ethylene) + fouling     148\n",
       "Poly(styrene)                 66\n",
       "Morphotype 1                  55\n",
       "Cellulose acetate             54\n",
       "Ethylene propylene rubber     49\n",
       "Poly(propylene) like          48\n",
       "PEVA                          43\n",
       "Poly(ethylene) like           25\n",
       "Poly(amide)                   21\n",
       "Cellulose like                16\n",
       "Morphotype 2                  11\n",
       "Unknown                        5\n",
       "PMMA                           3\n",
       "Poly(urethane)                 1\n",
       "Poly(vinylchloride)            1\n",
       "Animal fibre like              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpretation_counts = Kedzierski['Interpretation '].value_counts()\n",
    "interpretation_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_599/2197752154.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Kedzierski['Interpretation '] = Kedzierski['Interpretation '].replace('Poly(propylene) like', 'Poly(propylene)')\n",
      "/tmp/ipykernel_599/2197752154.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Kedzierski['Interpretation '] = Kedzierski['Interpretation '].replace('Cellulose like', 'Cellulose acetate')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interpretation</th>\n",
       "      <th>3995.98555</th>\n",
       "      <th>3994.05698</th>\n",
       "      <th>3992.12842</th>\n",
       "      <th>3990.19985</th>\n",
       "      <th>3988.27129</th>\n",
       "      <th>3986.34272</th>\n",
       "      <th>3984.41416</th>\n",
       "      <th>3982.4856</th>\n",
       "      <th>3980.55703</th>\n",
       "      <th>...</th>\n",
       "      <th>617.14062</th>\n",
       "      <th>615.21206</th>\n",
       "      <th>613.2835</th>\n",
       "      <th>611.35493</th>\n",
       "      <th>609.42637</th>\n",
       "      <th>607.4978</th>\n",
       "      <th>605.56924</th>\n",
       "      <th>603.64067</th>\n",
       "      <th>601.71211</th>\n",
       "      <th>599.78354</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cellulose acetate</td>\n",
       "      <td>-0.024702</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.032219</td>\n",
       "      <td>0.045128</td>\n",
       "      <td>0.046664</td>\n",
       "      <td>0.032280</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>-0.030605</td>\n",
       "      <td>...</td>\n",
       "      <td>2.623865</td>\n",
       "      <td>3.799876</td>\n",
       "      <td>4.907654</td>\n",
       "      <td>5.903986</td>\n",
       "      <td>7.259674</td>\n",
       "      <td>9.334074</td>\n",
       "      <td>11.783750</td>\n",
       "      <td>13.937754</td>\n",
       "      <td>15.418534</td>\n",
       "      <td>16.028218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cellulose acetate</td>\n",
       "      <td>-0.030687</td>\n",
       "      <td>-0.020140</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.072308</td>\n",
       "      <td>0.076775</td>\n",
       "      <td>0.059961</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134722</td>\n",
       "      <td>2.385143</td>\n",
       "      <td>3.963910</td>\n",
       "      <td>5.874066</td>\n",
       "      <td>8.291944</td>\n",
       "      <td>11.536771</td>\n",
       "      <td>14.967054</td>\n",
       "      <td>17.345409</td>\n",
       "      <td>18.209716</td>\n",
       "      <td>17.684628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cellulose acetate</td>\n",
       "      <td>-0.087176</td>\n",
       "      <td>-0.097008</td>\n",
       "      <td>-0.101351</td>\n",
       "      <td>-0.061781</td>\n",
       "      <td>0.021702</td>\n",
       "      <td>0.105184</td>\n",
       "      <td>0.117309</td>\n",
       "      <td>0.058075</td>\n",
       "      <td>-0.012137</td>\n",
       "      <td>...</td>\n",
       "      <td>6.068466</td>\n",
       "      <td>7.771580</td>\n",
       "      <td>8.914805</td>\n",
       "      <td>9.926292</td>\n",
       "      <td>11.322016</td>\n",
       "      <td>13.398389</td>\n",
       "      <td>15.831554</td>\n",
       "      <td>18.264719</td>\n",
       "      <td>20.258756</td>\n",
       "      <td>21.072635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cellulose acetate</td>\n",
       "      <td>-0.037723</td>\n",
       "      <td>-0.025146</td>\n",
       "      <td>-0.026624</td>\n",
       "      <td>-0.028102</td>\n",
       "      <td>-0.010841</td>\n",
       "      <td>0.020474</td>\n",
       "      <td>0.040078</td>\n",
       "      <td>0.024545</td>\n",
       "      <td>-0.005042</td>\n",
       "      <td>...</td>\n",
       "      <td>3.276646</td>\n",
       "      <td>4.012427</td>\n",
       "      <td>4.809110</td>\n",
       "      <td>5.929048</td>\n",
       "      <td>7.569003</td>\n",
       "      <td>9.717262</td>\n",
       "      <td>11.926425</td>\n",
       "      <td>13.838100</td>\n",
       "      <td>15.285976</td>\n",
       "      <td>15.949142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cellulose acetate</td>\n",
       "      <td>-0.023645</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.013337</td>\n",
       "      <td>0.021302</td>\n",
       "      <td>0.021584</td>\n",
       "      <td>0.016744</td>\n",
       "      <td>0.011904</td>\n",
       "      <td>...</td>\n",
       "      <td>3.420510</td>\n",
       "      <td>4.188933</td>\n",
       "      <td>5.169919</td>\n",
       "      <td>6.404445</td>\n",
       "      <td>7.787509</td>\n",
       "      <td>9.603384</td>\n",
       "      <td>11.839263</td>\n",
       "      <td>14.054654</td>\n",
       "      <td>15.622111</td>\n",
       "      <td>15.870649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.043015</td>\n",
       "      <td>-0.050403</td>\n",
       "      <td>-0.064003</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.075671</td>\n",
       "      <td>-0.042671</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.082360</td>\n",
       "      <td>0.161963</td>\n",
       "      <td>...</td>\n",
       "      <td>3.505148</td>\n",
       "      <td>3.457383</td>\n",
       "      <td>2.965346</td>\n",
       "      <td>2.445349</td>\n",
       "      <td>2.201856</td>\n",
       "      <td>1.694285</td>\n",
       "      <td>0.708268</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>0.243029</td>\n",
       "      <td>1.180117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.174344</td>\n",
       "      <td>-0.053499</td>\n",
       "      <td>0.067348</td>\n",
       "      <td>0.154828</td>\n",
       "      <td>0.186696</td>\n",
       "      <td>0.207442</td>\n",
       "      <td>0.261555</td>\n",
       "      <td>0.248934</td>\n",
       "      <td>0.136215</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.542803</td>\n",
       "      <td>-7.030846</td>\n",
       "      <td>-10.795946</td>\n",
       "      <td>-12.247627</td>\n",
       "      <td>-12.119956</td>\n",
       "      <td>-12.281461</td>\n",
       "      <td>-12.932345</td>\n",
       "      <td>-13.171705</td>\n",
       "      <td>-12.098646</td>\n",
       "      <td>-9.746533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0.011578</td>\n",
       "      <td>0.019579</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.014971</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>-0.005666</td>\n",
       "      <td>-0.002245</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920250</td>\n",
       "      <td>1.039209</td>\n",
       "      <td>1.166181</td>\n",
       "      <td>1.209574</td>\n",
       "      <td>1.239227</td>\n",
       "      <td>1.249415</td>\n",
       "      <td>1.218386</td>\n",
       "      <td>1.236588</td>\n",
       "      <td>1.281125</td>\n",
       "      <td>1.215747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.019956</td>\n",
       "      <td>-0.008994</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.026783</td>\n",
       "      <td>0.016549</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.013787</td>\n",
       "      <td>...</td>\n",
       "      <td>1.465810</td>\n",
       "      <td>1.571245</td>\n",
       "      <td>1.729672</td>\n",
       "      <td>1.806202</td>\n",
       "      <td>1.857681</td>\n",
       "      <td>1.917833</td>\n",
       "      <td>1.903797</td>\n",
       "      <td>1.848330</td>\n",
       "      <td>1.850673</td>\n",
       "      <td>1.860723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>-0.034746</td>\n",
       "      <td>-0.346008</td>\n",
       "      <td>-0.618305</td>\n",
       "      <td>-0.617845</td>\n",
       "      <td>-0.422560</td>\n",
       "      <td>-0.266240</td>\n",
       "      <td>-0.148885</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>0.475477</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.210188</td>\n",
       "      <td>-6.769197</td>\n",
       "      <td>-9.561998</td>\n",
       "      <td>-11.224809</td>\n",
       "      <td>-10.276952</td>\n",
       "      <td>-7.692558</td>\n",
       "      <td>-7.407109</td>\n",
       "      <td>-10.199910</td>\n",
       "      <td>-12.408233</td>\n",
       "      <td>-11.927959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964 rows × 1763 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Interpretation   3995.98555  3994.05698  3992.12842  3990.19985  \\\n",
       "1    Cellulose acetate   -0.024702    0.001853    0.017036    0.032219   \n",
       "2    Cellulose acetate   -0.030687   -0.020140    0.014730    0.049600   \n",
       "3    Cellulose acetate   -0.087176   -0.097008   -0.101351   -0.061781   \n",
       "4    Cellulose acetate   -0.037723   -0.025146   -0.026624   -0.028102   \n",
       "5    Cellulose acetate   -0.023645    0.002247    0.007651    0.007933   \n",
       "..                 ...         ...         ...         ...         ...   \n",
       "965            Unknown   -0.043015   -0.050403   -0.064003   -0.083818   \n",
       "966            Unknown   -0.174344   -0.053499    0.067348    0.154828   \n",
       "967            Unknown    0.011578    0.019579    0.023000    0.014971   \n",
       "968            Unknown   -0.019956   -0.008994    0.009676    0.023529   \n",
       "969            Unknown   -0.034746   -0.346008   -0.618305   -0.617845   \n",
       "\n",
       "     3988.27129  3986.34272  3984.41416  3982.4856  3980.55703  ...  \\\n",
       "1      0.045128    0.046664    0.032280  -0.000299   -0.030605  ...   \n",
       "2      0.072308    0.076775    0.059961   0.015784   -0.010152  ...   \n",
       "3      0.021702    0.105184    0.117309   0.058075   -0.012137  ...   \n",
       "4     -0.010841    0.020474    0.040078   0.024545   -0.005042  ...   \n",
       "5      0.013337    0.021302    0.021584   0.016744    0.011904  ...   \n",
       "..          ...         ...         ...        ...         ...  ...   \n",
       "965   -0.075671   -0.042671    0.005863   0.082360    0.161963  ...   \n",
       "966    0.186696    0.207442    0.261555   0.248934    0.136215  ...   \n",
       "967    0.001218   -0.005666   -0.002245   0.002321    0.000017  ...   \n",
       "968    0.026783    0.016549    0.003424   0.003788    0.013787  ...   \n",
       "969   -0.422560   -0.266240   -0.148885   0.007436    0.475477  ...   \n",
       "\n",
       "     617.14062  615.21206   613.2835  611.35493  609.42637   607.4978  \\\n",
       "1     2.623865   3.799876   4.907654   5.903986   7.259674   9.334074   \n",
       "2     1.134722   2.385143   3.963910   5.874066   8.291944  11.536771   \n",
       "3     6.068466   7.771580   8.914805   9.926292  11.322016  13.398389   \n",
       "4     3.276646   4.012427   4.809110   5.929048   7.569003   9.717262   \n",
       "5     3.420510   4.188933   5.169919   6.404445   7.787509   9.603384   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "965   3.505148   3.457383   2.965346   2.445349   2.201856   1.694285   \n",
       "966  -2.542803  -7.030846 -10.795946 -12.247627 -12.119956 -12.281461   \n",
       "967   0.920250   1.039209   1.166181   1.209574   1.239227   1.249415   \n",
       "968   1.465810   1.571245   1.729672   1.806202   1.857681   1.917833   \n",
       "969  -4.210188  -6.769197  -9.561998 -11.224809 -10.276952  -7.692558   \n",
       "\n",
       "     605.56924  603.64067  601.71211  599.78354  \n",
       "1    11.783750  13.937754  15.418534  16.028218  \n",
       "2    14.967054  17.345409  18.209716  17.684628  \n",
       "3    15.831554  18.264719  20.258756  21.072635  \n",
       "4    11.926425  13.838100  15.285976  15.949142  \n",
       "5    11.839263  14.054654  15.622111  15.870649  \n",
       "..         ...        ...        ...        ...  \n",
       "965   0.708268  -0.001245   0.243029   1.180117  \n",
       "966 -12.932345 -13.171705 -12.098646  -9.746533  \n",
       "967   1.218386   1.236588   1.281125   1.215747  \n",
       "968   1.903797   1.848330   1.850673   1.860723  \n",
       "969  -7.407109 -10.199910 -12.408233 -11.927959  \n",
       "\n",
       "[964 rows x 1763 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_to_remove = ['PMMA', 'Poly(urethane)', 'Poly(vinylchloride)', 'Animal fibre like']\n",
    "Kedzierski = Kedzierski[~Kedzierski['Interpretation '].isin(values_to_remove)]\n",
    "Kedzierski['Interpretation '] = Kedzierski['Interpretation '].replace('Poly(propylene) like', 'Poly(propylene)')\n",
    "Kedzierski['Interpretation '] = Kedzierski['Interpretation '].replace('Cellulose like', 'Cellulose acetate')\n",
    "Kedzierski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interpretation \n",
       "Poly(propylene)              243\n",
       "Poly(ethylene)               228\n",
       "Poly(ethylene) + fouling     148\n",
       "Cellulose acetate             70\n",
       "Poly(styrene)                 66\n",
       "Morphotype 1                  55\n",
       "Ethylene propylene rubber     49\n",
       "PEVA                          43\n",
       "Poly(ethylene) like           25\n",
       "Poly(amide)                   21\n",
       "Morphotype 2                  11\n",
       "Unknown                        5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpretation_counts = Kedzierski['Interpretation '].value_counts()\n",
    "interpretation_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_599/2974020699.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Kedzierski['Interpretation_encoded'] = label_encoder.fit_transform(Kedzierski['Interpretation '])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3995.98555</th>\n",
       "      <th>3994.05698</th>\n",
       "      <th>3992.12842</th>\n",
       "      <th>3990.19985</th>\n",
       "      <th>3988.27129</th>\n",
       "      <th>3986.34272</th>\n",
       "      <th>3984.41416</th>\n",
       "      <th>3982.4856</th>\n",
       "      <th>3980.55703</th>\n",
       "      <th>3978.62847</th>\n",
       "      <th>...</th>\n",
       "      <th>615.21206</th>\n",
       "      <th>613.2835</th>\n",
       "      <th>611.35493</th>\n",
       "      <th>609.42637</th>\n",
       "      <th>607.4978</th>\n",
       "      <th>605.56924</th>\n",
       "      <th>603.64067</th>\n",
       "      <th>601.71211</th>\n",
       "      <th>599.78354</th>\n",
       "      <th>Interpretation_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.024702</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.032219</td>\n",
       "      <td>0.045128</td>\n",
       "      <td>0.046664</td>\n",
       "      <td>0.032280</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>-0.030605</td>\n",
       "      <td>-0.029068</td>\n",
       "      <td>...</td>\n",
       "      <td>3.799876</td>\n",
       "      <td>4.907654</td>\n",
       "      <td>5.903986</td>\n",
       "      <td>7.259674</td>\n",
       "      <td>9.334074</td>\n",
       "      <td>11.783750</td>\n",
       "      <td>13.937754</td>\n",
       "      <td>15.418534</td>\n",
       "      <td>16.028218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.030687</td>\n",
       "      <td>-0.020140</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.072308</td>\n",
       "      <td>0.076775</td>\n",
       "      <td>0.059961</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>...</td>\n",
       "      <td>2.385143</td>\n",
       "      <td>3.963910</td>\n",
       "      <td>5.874066</td>\n",
       "      <td>8.291944</td>\n",
       "      <td>11.536771</td>\n",
       "      <td>14.967054</td>\n",
       "      <td>17.345409</td>\n",
       "      <td>18.209716</td>\n",
       "      <td>17.684628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.087176</td>\n",
       "      <td>-0.097008</td>\n",
       "      <td>-0.101351</td>\n",
       "      <td>-0.061781</td>\n",
       "      <td>0.021702</td>\n",
       "      <td>0.105184</td>\n",
       "      <td>0.117309</td>\n",
       "      <td>0.058075</td>\n",
       "      <td>-0.012137</td>\n",
       "      <td>-0.016480</td>\n",
       "      <td>...</td>\n",
       "      <td>7.771580</td>\n",
       "      <td>8.914805</td>\n",
       "      <td>9.926292</td>\n",
       "      <td>11.322016</td>\n",
       "      <td>13.398389</td>\n",
       "      <td>15.831554</td>\n",
       "      <td>18.264719</td>\n",
       "      <td>20.258756</td>\n",
       "      <td>21.072635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.037723</td>\n",
       "      <td>-0.025146</td>\n",
       "      <td>-0.026624</td>\n",
       "      <td>-0.028102</td>\n",
       "      <td>-0.010841</td>\n",
       "      <td>0.020474</td>\n",
       "      <td>0.040078</td>\n",
       "      <td>0.024545</td>\n",
       "      <td>-0.005042</td>\n",
       "      <td>-0.015890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.012427</td>\n",
       "      <td>4.809110</td>\n",
       "      <td>5.929048</td>\n",
       "      <td>7.569003</td>\n",
       "      <td>9.717262</td>\n",
       "      <td>11.926425</td>\n",
       "      <td>13.838100</td>\n",
       "      <td>15.285976</td>\n",
       "      <td>15.949142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.023645</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.013337</td>\n",
       "      <td>0.021302</td>\n",
       "      <td>0.021584</td>\n",
       "      <td>0.016744</td>\n",
       "      <td>0.011904</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>...</td>\n",
       "      <td>4.188933</td>\n",
       "      <td>5.169919</td>\n",
       "      <td>6.404445</td>\n",
       "      <td>7.787509</td>\n",
       "      <td>9.603384</td>\n",
       "      <td>11.839263</td>\n",
       "      <td>14.054654</td>\n",
       "      <td>15.622111</td>\n",
       "      <td>15.870649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>-0.043015</td>\n",
       "      <td>-0.050403</td>\n",
       "      <td>-0.064003</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.075671</td>\n",
       "      <td>-0.042671</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.082360</td>\n",
       "      <td>0.161963</td>\n",
       "      <td>0.188749</td>\n",
       "      <td>...</td>\n",
       "      <td>3.457383</td>\n",
       "      <td>2.965346</td>\n",
       "      <td>2.445349</td>\n",
       "      <td>2.201856</td>\n",
       "      <td>1.694285</td>\n",
       "      <td>0.708268</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>0.243029</td>\n",
       "      <td>1.180117</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>-0.174344</td>\n",
       "      <td>-0.053499</td>\n",
       "      <td>0.067348</td>\n",
       "      <td>0.154828</td>\n",
       "      <td>0.186696</td>\n",
       "      <td>0.207442</td>\n",
       "      <td>0.261555</td>\n",
       "      <td>0.248934</td>\n",
       "      <td>0.136215</td>\n",
       "      <td>0.123594</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.030846</td>\n",
       "      <td>-10.795946</td>\n",
       "      <td>-12.247627</td>\n",
       "      <td>-12.119956</td>\n",
       "      <td>-12.281461</td>\n",
       "      <td>-12.932345</td>\n",
       "      <td>-13.171705</td>\n",
       "      <td>-12.098646</td>\n",
       "      <td>-9.746533</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>0.011578</td>\n",
       "      <td>0.019579</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.014971</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>-0.005666</td>\n",
       "      <td>-0.002245</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.003432</td>\n",
       "      <td>...</td>\n",
       "      <td>1.039209</td>\n",
       "      <td>1.166181</td>\n",
       "      <td>1.209574</td>\n",
       "      <td>1.239227</td>\n",
       "      <td>1.249415</td>\n",
       "      <td>1.218386</td>\n",
       "      <td>1.236588</td>\n",
       "      <td>1.281125</td>\n",
       "      <td>1.215747</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>-0.019956</td>\n",
       "      <td>-0.008994</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.026783</td>\n",
       "      <td>0.016549</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.013787</td>\n",
       "      <td>0.017042</td>\n",
       "      <td>...</td>\n",
       "      <td>1.571245</td>\n",
       "      <td>1.729672</td>\n",
       "      <td>1.806202</td>\n",
       "      <td>1.857681</td>\n",
       "      <td>1.917833</td>\n",
       "      <td>1.903797</td>\n",
       "      <td>1.848330</td>\n",
       "      <td>1.850673</td>\n",
       "      <td>1.860723</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>-0.034746</td>\n",
       "      <td>-0.346008</td>\n",
       "      <td>-0.618305</td>\n",
       "      <td>-0.617845</td>\n",
       "      <td>-0.422560</td>\n",
       "      <td>-0.266240</td>\n",
       "      <td>-0.148885</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>0.475477</td>\n",
       "      <td>1.372136</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.769197</td>\n",
       "      <td>-9.561998</td>\n",
       "      <td>-11.224809</td>\n",
       "      <td>-10.276952</td>\n",
       "      <td>-7.692558</td>\n",
       "      <td>-7.407109</td>\n",
       "      <td>-10.199910</td>\n",
       "      <td>-12.408233</td>\n",
       "      <td>-11.927959</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>964 rows × 1763 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     3995.98555  3994.05698  3992.12842  3990.19985  3988.27129  3986.34272  \\\n",
       "1     -0.024702    0.001853    0.017036    0.032219    0.045128    0.046664   \n",
       "2     -0.030687   -0.020140    0.014730    0.049600    0.072308    0.076775   \n",
       "3     -0.087176   -0.097008   -0.101351   -0.061781    0.021702    0.105184   \n",
       "4     -0.037723   -0.025146   -0.026624   -0.028102   -0.010841    0.020474   \n",
       "5     -0.023645    0.002247    0.007651    0.007933    0.013337    0.021302   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "965   -0.043015   -0.050403   -0.064003   -0.083818   -0.075671   -0.042671   \n",
       "966   -0.174344   -0.053499    0.067348    0.154828    0.186696    0.207442   \n",
       "967    0.011578    0.019579    0.023000    0.014971    0.001218   -0.005666   \n",
       "968   -0.019956   -0.008994    0.009676    0.023529    0.026783    0.016549   \n",
       "969   -0.034746   -0.346008   -0.618305   -0.617845   -0.422560   -0.266240   \n",
       "\n",
       "     3984.41416  3982.4856  3980.55703  3978.62847  ...  615.21206   613.2835  \\\n",
       "1      0.032280  -0.000299   -0.030605   -0.029068  ...   3.799876   4.907654   \n",
       "2      0.059961   0.015784   -0.010152    0.003436  ...   2.385143   3.963910   \n",
       "3      0.117309   0.058075   -0.012137   -0.016480  ...   7.771580   8.914805   \n",
       "4      0.040078   0.024545   -0.005042   -0.015890  ...   4.012427   4.809110   \n",
       "5      0.021584   0.016744    0.011904    0.014747  ...   4.188933   5.169919   \n",
       "..          ...        ...         ...         ...  ...        ...        ...   \n",
       "965    0.005863   0.082360    0.161963    0.188749  ...   3.457383   2.965346   \n",
       "966    0.261555   0.248934    0.136215    0.123594  ...  -7.030846 -10.795946   \n",
       "967   -0.002245   0.002321    0.000017   -0.003432  ...   1.039209   1.166181   \n",
       "968    0.003424   0.003788    0.013787    0.017042  ...   1.571245   1.729672   \n",
       "969   -0.148885   0.007436    0.475477    1.372136  ...  -6.769197  -9.561998   \n",
       "\n",
       "     611.35493  609.42637   607.4978  605.56924  603.64067  601.71211  \\\n",
       "1     5.903986   7.259674   9.334074  11.783750  13.937754  15.418534   \n",
       "2     5.874066   8.291944  11.536771  14.967054  17.345409  18.209716   \n",
       "3     9.926292  11.322016  13.398389  15.831554  18.264719  20.258756   \n",
       "4     5.929048   7.569003   9.717262  11.926425  13.838100  15.285976   \n",
       "5     6.404445   7.787509   9.603384  11.839263  14.054654  15.622111   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "965   2.445349   2.201856   1.694285   0.708268  -0.001245   0.243029   \n",
       "966 -12.247627 -12.119956 -12.281461 -12.932345 -13.171705 -12.098646   \n",
       "967   1.209574   1.239227   1.249415   1.218386   1.236588   1.281125   \n",
       "968   1.806202   1.857681   1.917833   1.903797   1.848330   1.850673   \n",
       "969 -11.224809 -10.276952  -7.692558  -7.407109 -10.199910 -12.408233   \n",
       "\n",
       "     599.78354  Interpretation_encoded  \n",
       "1    16.028218                       0  \n",
       "2    17.684628                       0  \n",
       "3    21.072635                       0  \n",
       "4    15.949142                       0  \n",
       "5    15.870649                       0  \n",
       "..         ...                     ...  \n",
       "965   1.180117                      11  \n",
       "966  -9.746533                      11  \n",
       "967   1.215747                      11  \n",
       "968   1.860723                      11  \n",
       "969 -11.927959                      11  \n",
       "\n",
       "[964 rows x 1763 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Interpretation' column\n",
    "Kedzierski['Interpretation_encoded'] = label_encoder.fit_transform(Kedzierski['Interpretation '])\n",
    "Kedzierski = Kedzierski.drop(columns=['Interpretation '])\n",
    "Kedzierski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Kedzierski.drop(columns=['Interpretation_encoded'])\n",
    "Y = Kedzierski['Interpretation_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(964, 9)\n",
      "Explained Variance Ratio of each principal component:\n",
      "[0.43904799 0.18681138 0.09314351 0.07201679 0.05131966 0.04641061\n",
      " 0.02171613 0.01427455 0.01371616]\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer(norm='max')\n",
    "data_scaled = normalizer.fit_transform(X)\n",
    "pca = PCA(n_components=9)\n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "print(data_pca.shape)\n",
    "\n",
    "# Check how much variance each component explains\n",
    "print(\"Explained Variance Ratio of each principal component:\")\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = ExtraTreesClassifier(\n",
    "    n_estimators=500, max_depth=35, min_samples_split=7, min_samples_leaf=1, max_features='sqrt', random_state=42\n",
    ")\n",
    "clf2 = DecisionTreeClassifier(\n",
    "    max_depth=15, min_samples_split=14, min_samples_leaf=5, criterion='entropy', random_state=42\n",
    ")\n",
    "clf3 = SVC(\n",
    "    C=42.26721781758463, kernel='rbf', gamma='auto', probability=True, random_state=42\n",
    ")\n",
    "clf4 = xgb.XGBClassifier(\n",
    "    n_estimators=900, max_depth=9, learning_rate=0.21577743453773293,\n",
    "    subsample=0.7134596184717141, colsample_bytree=0.8926104458835206, \n",
    "    gamma=0.06934334083160099, reg_alpha=0.6613878247418032, reg_lambda=0.26856628937579974,\n",
    "    random_state=42, use_label_encoder=False, eval_metric='mlogloss'\n",
    ")\n",
    "clf5 = lgb.LGBMClassifier(\n",
    "    n_estimators=700, max_depth=7, learning_rate=0.0855852309100438, num_leaves=138, \n",
    "    min_child_samples=62, subsample=0.9673844529941501, colsample_bytree=0.7343207921501621,\n",
    "    reg_alpha=0.2369598754789148, reg_lambda=0.5701128436794478, random_state=42\n",
    ")\n",
    "clf6 = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=30, min_samples_split=4, min_samples_leaf=1, \n",
    "    max_features='log2', bootstrap=True, random_state=42\n",
    ")\n",
    "clf9 = GradientBoostingClassifier(\n",
    "    n_estimators=200, learning_rate=0.17387802436141037, max_depth=10, \n",
    "    min_samples_split=12, min_samples_leaf=6, subsample=0.547399138004244, \n",
    "    max_features='sqrt', loss='log_loss', random_state=42\n",
    ")\n",
    "clf10 = AdaBoostClassifier(\n",
    "    n_estimators=500, learning_rate=0.6574797025901895, algorithm='SAMME.R', random_state=42\n",
    ")\n",
    "clf11 = cb.CatBoostClassifier(\n",
    "    n_estimators=600, learning_rate=0.07472477144852825, max_depth=10, min_data_in_leaf=9, \n",
    "    l2_leaf_reg=7.404283846568703, border_count=192, silent=True, random_state=42\n",
    ")\n",
    "clf12 = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 128), activation='relu', solver='lbfgs', \n",
    "    alpha=0.09632315546143085, learning_rate='invscaling', max_iter=1800, random_state=42\n",
    ")\n",
    "\n",
    "# Stacking ensemble\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('et', clf1), ('dt', clf2), ('svc', clf3), ('xgb', clf4), \n",
    "        ('lgbm', clf5), ('rf', clf6), ('gb', clf9), \n",
    "        ('ab', clf10), ('catboost', clf11), ('mlp', clf12)\n",
    "    ],\n",
    "    final_estimator=ExtraTreesClassifier(\n",
    "    n_estimators=500, max_depth=35, min_samples_split=7, min_samples_leaf=1, max_features='sqrt', random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('model', stacking_clf)  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.9588\n",
      "  F1 Score: 0.9554\n",
      "  Precision: 0.9574\n",
      "  Recall: 0.9588\n",
      "  Cohen's Kappa: 0.9508\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n",
      "  Accuracy: 0.9278\n",
      "  F1 Score: 0.9182\n",
      "  Precision: 0.9176\n",
      "  Recall: 0.9278\n",
      "  Cohen's Kappa: 0.9132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3:\n",
      "  Accuracy: 0.9691\n",
      "  F1 Score: 0.9675\n",
      "  Precision: 0.9712\n",
      "  Recall: 0.9691\n",
      "  Cohen's Kappa: 0.9628\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4:\n",
      "  Accuracy: 0.9485\n",
      "  F1 Score: 0.9410\n",
      "  Precision: 0.9452\n",
      "  Recall: 0.9485\n",
      "  Cohen's Kappa: 0.9383\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5:\n",
      "  Accuracy: 0.9375\n",
      "  F1 Score: 0.9348\n",
      "  Precision: 0.9468\n",
      "  Recall: 0.9375\n",
      "  Cohen's Kappa: 0.9246\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6:\n",
      "  Accuracy: 0.9583\n",
      "  F1 Score: 0.9584\n",
      "  Precision: 0.9601\n",
      "  Recall: 0.9583\n",
      "  Cohen's Kappa: 0.9502\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7:\n",
      "  Accuracy: 0.9167\n",
      "  F1 Score: 0.9170\n",
      "  Precision: 0.9275\n",
      "  Recall: 0.9167\n",
      "  Cohen's Kappa: 0.9006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8:\n",
      "  Accuracy: 0.9688\n",
      "  F1 Score: 0.9686\n",
      "  Precision: 0.9709\n",
      "  Recall: 0.9688\n",
      "  Cohen's Kappa: 0.9627\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9:\n",
      "  Accuracy: 0.9271\n",
      "  F1 Score: 0.9214\n",
      "  Precision: 0.9228\n",
      "  Recall: 0.9271\n",
      "  Cohen's Kappa: 0.9133\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10:\n",
      "  Accuracy: 0.9583\n",
      "  F1 Score: 0.9537\n",
      "  Precision: 0.9519\n",
      "  Recall: 0.9583\n",
      "  Cohen's Kappa: 0.9505\n",
      "\n",
      "Overall Results:\n",
      "Mean Accuracy: 0.9471, Std Dev: 0.0177\n",
      "Mean F1 Score: 0.9436, Std Dev: 0.0189\n",
      "Mean Precision: 0.9472, Std Dev: 0.0182\n",
      "Mean Recall: 0.9471, Std Dev: 0.0177\n",
      "Mean Cohen's Kappa: 0.9367, Std Dev: 0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=60)\n",
    "\n",
    "Y = Y.to_numpy() if isinstance(Y, pd.Series) else Y\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "kappas = []\n",
    "\n",
    "fold_idx = 1\n",
    "for train_idx, test_idx in cv.split(data_pca, Y):\n",
    "    X_train, X_test = data_pca[train_idx], data_pca[test_idx]\n",
    "    y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "    \n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    y_pred = stacking_clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    kappas.append(kappa)\n",
    "\n",
    "    print(f\"Fold {fold_idx}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  Cohen's Kappa: {kappa:.4f}\\n\")\n",
    "    fold_idx += 1\n",
    "\n",
    "print(\"Overall Results:\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f}, Std Dev: {np.std(accuracies):.4f}\")\n",
    "print(f\"Mean F1 Score: {np.mean(f1_scores):.4f}, Std Dev: {np.std(f1_scores):.4f}\")\n",
    "print(f\"Mean Precision: {np.mean(precisions):.4f}, Std Dev: {np.std(precisions):.4f}\")\n",
    "print(f\"Mean Recall: {np.mean(recalls):.4f}, Std Dev: {np.std(recalls):.4f}\")\n",
    "print(f\"Mean Cohen's Kappa: {np.mean(kappas):.4f}, Std Dev: {np.std(kappas):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AliHaq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
