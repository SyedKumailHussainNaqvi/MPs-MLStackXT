{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, StackingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identified</th>\n",
       "      <th>4000</th>\n",
       "      <th>3999</th>\n",
       "      <th>3998</th>\n",
       "      <th>3997</th>\n",
       "      <th>3996</th>\n",
       "      <th>3995</th>\n",
       "      <th>3994</th>\n",
       "      <th>3993</th>\n",
       "      <th>3992</th>\n",
       "      <th>...</th>\n",
       "      <th>459</th>\n",
       "      <th>458</th>\n",
       "      <th>457</th>\n",
       "      <th>456</th>\n",
       "      <th>455</th>\n",
       "      <th>454</th>\n",
       "      <th>453</th>\n",
       "      <th>452</th>\n",
       "      <th>451</th>\n",
       "      <th>450</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDPE</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>...</td>\n",
       "      <td>96.83</td>\n",
       "      <td>96.84</td>\n",
       "      <td>96.85</td>\n",
       "      <td>96.83</td>\n",
       "      <td>96.77</td>\n",
       "      <td>96.66</td>\n",
       "      <td>96.54</td>\n",
       "      <td>96.46</td>\n",
       "      <td>96.43</td>\n",
       "      <td>96.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PP</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>...</td>\n",
       "      <td>93.80</td>\n",
       "      <td>93.77</td>\n",
       "      <td>93.86</td>\n",
       "      <td>94.01</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.08</td>\n",
       "      <td>94.12</td>\n",
       "      <td>94.23</td>\n",
       "      <td>94.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PP</td>\n",
       "      <td>99.23</td>\n",
       "      <td>99.22</td>\n",
       "      <td>99.22</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.20</td>\n",
       "      <td>99.20</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.21</td>\n",
       "      <td>...</td>\n",
       "      <td>93.98</td>\n",
       "      <td>94.00</td>\n",
       "      <td>94.05</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.14</td>\n",
       "      <td>94.23</td>\n",
       "      <td>94.38</td>\n",
       "      <td>94.57</td>\n",
       "      <td>94.75</td>\n",
       "      <td>94.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mixture</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>...</td>\n",
       "      <td>96.41</td>\n",
       "      <td>96.45</td>\n",
       "      <td>96.50</td>\n",
       "      <td>96.55</td>\n",
       "      <td>96.62</td>\n",
       "      <td>96.68</td>\n",
       "      <td>96.74</td>\n",
       "      <td>96.77</td>\n",
       "      <td>96.78</td>\n",
       "      <td>96.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDPE</td>\n",
       "      <td>99.55</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>...</td>\n",
       "      <td>95.28</td>\n",
       "      <td>95.22</td>\n",
       "      <td>95.23</td>\n",
       "      <td>95.30</td>\n",
       "      <td>95.38</td>\n",
       "      <td>95.41</td>\n",
       "      <td>95.35</td>\n",
       "      <td>95.24</td>\n",
       "      <td>95.21</td>\n",
       "      <td>95.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>PP</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.74</td>\n",
       "      <td>99.74</td>\n",
       "      <td>99.73</td>\n",
       "      <td>...</td>\n",
       "      <td>98.58</td>\n",
       "      <td>98.58</td>\n",
       "      <td>98.65</td>\n",
       "      <td>98.76</td>\n",
       "      <td>98.85</td>\n",
       "      <td>98.88</td>\n",
       "      <td>98.87</td>\n",
       "      <td>98.87</td>\n",
       "      <td>98.92</td>\n",
       "      <td>98.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>Mixture</td>\n",
       "      <td>99.62</td>\n",
       "      <td>99.62</td>\n",
       "      <td>99.62</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>...</td>\n",
       "      <td>97.02</td>\n",
       "      <td>97.08</td>\n",
       "      <td>97.16</td>\n",
       "      <td>97.23</td>\n",
       "      <td>97.27</td>\n",
       "      <td>97.30</td>\n",
       "      <td>97.32</td>\n",
       "      <td>97.34</td>\n",
       "      <td>97.39</td>\n",
       "      <td>97.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Mixture</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.93</td>\n",
       "      <td>...</td>\n",
       "      <td>96.94</td>\n",
       "      <td>97.01</td>\n",
       "      <td>97.05</td>\n",
       "      <td>97.07</td>\n",
       "      <td>97.08</td>\n",
       "      <td>97.06</td>\n",
       "      <td>97.01</td>\n",
       "      <td>96.97</td>\n",
       "      <td>96.97</td>\n",
       "      <td>97.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>HDPE</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.57</td>\n",
       "      <td>...</td>\n",
       "      <td>94.32</td>\n",
       "      <td>94.38</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.51</td>\n",
       "      <td>94.52</td>\n",
       "      <td>94.52</td>\n",
       "      <td>94.53</td>\n",
       "      <td>94.51</td>\n",
       "      <td>94.42</td>\n",
       "      <td>94.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>HDPE</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>98.99</td>\n",
       "      <td>98.98</td>\n",
       "      <td>98.99</td>\n",
       "      <td>98.98</td>\n",
       "      <td>98.99</td>\n",
       "      <td>98.99</td>\n",
       "      <td>99.00</td>\n",
       "      <td>...</td>\n",
       "      <td>95.97</td>\n",
       "      <td>96.02</td>\n",
       "      <td>96.05</td>\n",
       "      <td>96.05</td>\n",
       "      <td>96.02</td>\n",
       "      <td>95.98</td>\n",
       "      <td>95.90</td>\n",
       "      <td>95.80</td>\n",
       "      <td>95.75</td>\n",
       "      <td>95.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 3552 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    identified   4000   3999   3998   3997   3996   3995   3994   3993   3992  \\\n",
       "0         HDPE  99.51  99.51  99.51  99.51  99.51  99.50  99.50  99.50  99.50   \n",
       "1           PP  99.03  99.03  99.03  99.03  99.02  99.02  99.02  99.02  99.02   \n",
       "2           PP  99.23  99.22  99.22  99.21  99.21  99.20  99.20  99.21  99.21   \n",
       "3      Mixture  99.50  99.50  99.50  99.50  99.51  99.51  99.51  99.51  99.51   \n",
       "4         HDPE  99.55  99.56  99.56  99.57  99.57  99.57  99.56  99.56  99.56   \n",
       "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "795         PP  99.75  99.75  99.75  99.75  99.75  99.75  99.74  99.74  99.73   \n",
       "796    Mixture  99.62  99.62  99.62  99.63  99.63  99.63  99.63  99.63  99.63   \n",
       "797    Mixture  99.92  99.92  99.92  99.92  99.92  99.92  99.92  99.93  99.93   \n",
       "798       HDPE  99.58  99.58  99.58  99.58  99.58  99.58  99.58  99.58  99.57   \n",
       "799       HDPE  99.00  99.00  98.99  98.98  98.99  98.98  98.99  98.99  99.00   \n",
       "\n",
       "     ...    459    458    457    456    455    454    453    452    451    450  \n",
       "0    ...  96.83  96.84  96.85  96.83  96.77  96.66  96.54  96.46  96.43  96.44  \n",
       "1    ...  93.80  93.77  93.86  94.01  94.09  94.09  94.08  94.12  94.23  94.36  \n",
       "2    ...  93.98  94.00  94.05  94.09  94.14  94.23  94.38  94.57  94.75  94.87  \n",
       "3    ...  96.41  96.45  96.50  96.55  96.62  96.68  96.74  96.77  96.78  96.80  \n",
       "4    ...  95.28  95.22  95.23  95.30  95.38  95.41  95.35  95.24  95.21  95.07  \n",
       "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "795  ...  98.58  98.58  98.65  98.76  98.85  98.88  98.87  98.87  98.92  98.98  \n",
       "796  ...  97.02  97.08  97.16  97.23  97.27  97.30  97.32  97.34  97.39  97.47  \n",
       "797  ...  96.94  97.01  97.05  97.07  97.08  97.06  97.01  96.97  96.97  97.02  \n",
       "798  ...  94.32  94.38  94.46  94.51  94.52  94.52  94.53  94.51  94.42  94.31  \n",
       "799  ...  95.97  96.02  96.05  96.05  96.02  95.98  95.90  95.80  95.75  95.75  \n",
       "\n",
       "[800 rows x 3552 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jung = pd.read_csv(\"/home/kumail/Energy_AI/Micro Palstic/Dataset/Jung et Dataset.csv\")\n",
    "Jung = Jung.drop(columns=['Turtle_piece.scan'])\n",
    "Jung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "identified\n",
       "HDPE       438\n",
       "PP         272\n",
       "Mixture     39\n",
       "LDPE        37\n",
       "PS           7\n",
       "Unknown      4\n",
       "Nylon        1\n",
       "PVC          1\n",
       "PETE         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jung_counts = Jung['identified'].value_counts()\n",
    "Jung_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40851/832293166.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Jung['identified'] = Jung['identified'].replace('PS', 'Unknown')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "identified\n",
       "HDPE       438\n",
       "PP         272\n",
       "Mixture     39\n",
       "LDPE        37\n",
       "Unknown     11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_to_remove = ['Nylon', 'PVC', 'PETE']\n",
    "Jung = Jung[~Jung['identified'].isin(values_to_remove)]\n",
    "Jung['identified'] = Jung['identified'].replace('PS', 'Unknown')\n",
    "Jung_counts = Jung['identified'].value_counts()\n",
    "Jung_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40851/1603336163.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Jung['identified_encoded'] = label_encoder.fit_transform(Jung['identified'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4000</th>\n",
       "      <th>3999</th>\n",
       "      <th>3998</th>\n",
       "      <th>3997</th>\n",
       "      <th>3996</th>\n",
       "      <th>3995</th>\n",
       "      <th>3994</th>\n",
       "      <th>3993</th>\n",
       "      <th>3992</th>\n",
       "      <th>3991</th>\n",
       "      <th>...</th>\n",
       "      <th>458</th>\n",
       "      <th>457</th>\n",
       "      <th>456</th>\n",
       "      <th>455</th>\n",
       "      <th>454</th>\n",
       "      <th>453</th>\n",
       "      <th>452</th>\n",
       "      <th>451</th>\n",
       "      <th>450</th>\n",
       "      <th>identified_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.51</td>\n",
       "      <td>...</td>\n",
       "      <td>96.84</td>\n",
       "      <td>96.85</td>\n",
       "      <td>96.83</td>\n",
       "      <td>96.77</td>\n",
       "      <td>96.66</td>\n",
       "      <td>96.54</td>\n",
       "      <td>96.46</td>\n",
       "      <td>96.43</td>\n",
       "      <td>96.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.03</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.03</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>99.02</td>\n",
       "      <td>...</td>\n",
       "      <td>93.77</td>\n",
       "      <td>93.86</td>\n",
       "      <td>94.01</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.08</td>\n",
       "      <td>94.12</td>\n",
       "      <td>94.23</td>\n",
       "      <td>94.36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.23</td>\n",
       "      <td>99.22</td>\n",
       "      <td>99.22</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.20</td>\n",
       "      <td>99.20</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.21</td>\n",
       "      <td>99.22</td>\n",
       "      <td>...</td>\n",
       "      <td>94.00</td>\n",
       "      <td>94.05</td>\n",
       "      <td>94.09</td>\n",
       "      <td>94.14</td>\n",
       "      <td>94.23</td>\n",
       "      <td>94.38</td>\n",
       "      <td>94.57</td>\n",
       "      <td>94.75</td>\n",
       "      <td>94.87</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>99.51</td>\n",
       "      <td>...</td>\n",
       "      <td>96.45</td>\n",
       "      <td>96.50</td>\n",
       "      <td>96.55</td>\n",
       "      <td>96.62</td>\n",
       "      <td>96.68</td>\n",
       "      <td>96.74</td>\n",
       "      <td>96.77</td>\n",
       "      <td>96.78</td>\n",
       "      <td>96.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.55</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>99.56</td>\n",
       "      <td>...</td>\n",
       "      <td>95.22</td>\n",
       "      <td>95.23</td>\n",
       "      <td>95.30</td>\n",
       "      <td>95.38</td>\n",
       "      <td>95.41</td>\n",
       "      <td>95.35</td>\n",
       "      <td>95.24</td>\n",
       "      <td>95.21</td>\n",
       "      <td>95.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.75</td>\n",
       "      <td>99.74</td>\n",
       "      <td>99.74</td>\n",
       "      <td>99.73</td>\n",
       "      <td>99.73</td>\n",
       "      <td>...</td>\n",
       "      <td>98.58</td>\n",
       "      <td>98.65</td>\n",
       "      <td>98.76</td>\n",
       "      <td>98.85</td>\n",
       "      <td>98.88</td>\n",
       "      <td>98.87</td>\n",
       "      <td>98.87</td>\n",
       "      <td>98.92</td>\n",
       "      <td>98.98</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>99.62</td>\n",
       "      <td>99.62</td>\n",
       "      <td>99.62</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.63</td>\n",
       "      <td>99.64</td>\n",
       "      <td>...</td>\n",
       "      <td>97.08</td>\n",
       "      <td>97.16</td>\n",
       "      <td>97.23</td>\n",
       "      <td>97.27</td>\n",
       "      <td>97.30</td>\n",
       "      <td>97.32</td>\n",
       "      <td>97.34</td>\n",
       "      <td>97.39</td>\n",
       "      <td>97.47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.92</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.93</td>\n",
       "      <td>99.93</td>\n",
       "      <td>...</td>\n",
       "      <td>97.01</td>\n",
       "      <td>97.05</td>\n",
       "      <td>97.07</td>\n",
       "      <td>97.08</td>\n",
       "      <td>97.06</td>\n",
       "      <td>97.01</td>\n",
       "      <td>96.97</td>\n",
       "      <td>96.97</td>\n",
       "      <td>97.02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.58</td>\n",
       "      <td>99.57</td>\n",
       "      <td>99.57</td>\n",
       "      <td>...</td>\n",
       "      <td>94.38</td>\n",
       "      <td>94.46</td>\n",
       "      <td>94.51</td>\n",
       "      <td>94.52</td>\n",
       "      <td>94.52</td>\n",
       "      <td>94.53</td>\n",
       "      <td>94.51</td>\n",
       "      <td>94.42</td>\n",
       "      <td>94.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>98.99</td>\n",
       "      <td>98.98</td>\n",
       "      <td>98.99</td>\n",
       "      <td>98.98</td>\n",
       "      <td>98.99</td>\n",
       "      <td>98.99</td>\n",
       "      <td>99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>...</td>\n",
       "      <td>96.02</td>\n",
       "      <td>96.05</td>\n",
       "      <td>96.05</td>\n",
       "      <td>96.02</td>\n",
       "      <td>95.98</td>\n",
       "      <td>95.90</td>\n",
       "      <td>95.80</td>\n",
       "      <td>95.75</td>\n",
       "      <td>95.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>797 rows × 3552 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      4000   3999   3998   3997   3996   3995   3994   3993   3992   3991  \\\n",
       "0    99.51  99.51  99.51  99.51  99.51  99.50  99.50  99.50  99.50  99.51   \n",
       "1    99.03  99.03  99.03  99.03  99.02  99.02  99.02  99.02  99.02  99.02   \n",
       "2    99.23  99.22  99.22  99.21  99.21  99.20  99.20  99.21  99.21  99.22   \n",
       "3    99.50  99.50  99.50  99.50  99.51  99.51  99.51  99.51  99.51  99.51   \n",
       "4    99.55  99.56  99.56  99.57  99.57  99.57  99.56  99.56  99.56  99.56   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "795  99.75  99.75  99.75  99.75  99.75  99.75  99.74  99.74  99.73  99.73   \n",
       "796  99.62  99.62  99.62  99.63  99.63  99.63  99.63  99.63  99.63  99.64   \n",
       "797  99.92  99.92  99.92  99.92  99.92  99.92  99.92  99.93  99.93  99.93   \n",
       "798  99.58  99.58  99.58  99.58  99.58  99.58  99.58  99.58  99.57  99.57   \n",
       "799  99.00  99.00  98.99  98.98  98.99  98.98  98.99  98.99  99.00  99.00   \n",
       "\n",
       "     ...    458    457    456    455    454    453    452    451    450  \\\n",
       "0    ...  96.84  96.85  96.83  96.77  96.66  96.54  96.46  96.43  96.44   \n",
       "1    ...  93.77  93.86  94.01  94.09  94.09  94.08  94.12  94.23  94.36   \n",
       "2    ...  94.00  94.05  94.09  94.14  94.23  94.38  94.57  94.75  94.87   \n",
       "3    ...  96.45  96.50  96.55  96.62  96.68  96.74  96.77  96.78  96.80   \n",
       "4    ...  95.22  95.23  95.30  95.38  95.41  95.35  95.24  95.21  95.07   \n",
       "..   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "795  ...  98.58  98.65  98.76  98.85  98.88  98.87  98.87  98.92  98.98   \n",
       "796  ...  97.08  97.16  97.23  97.27  97.30  97.32  97.34  97.39  97.47   \n",
       "797  ...  97.01  97.05  97.07  97.08  97.06  97.01  96.97  96.97  97.02   \n",
       "798  ...  94.38  94.46  94.51  94.52  94.52  94.53  94.51  94.42  94.31   \n",
       "799  ...  96.02  96.05  96.05  96.02  95.98  95.90  95.80  95.75  95.75   \n",
       "\n",
       "     identified_encoded  \n",
       "0                     0  \n",
       "1                     3  \n",
       "2                     3  \n",
       "3                     2  \n",
       "4                     0  \n",
       "..                  ...  \n",
       "795                   3  \n",
       "796                   2  \n",
       "797                   2  \n",
       "798                   0  \n",
       "799                   0  \n",
       "\n",
       "[797 rows x 3552 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Interpretation' column\n",
    "Jung['identified_encoded'] = label_encoder.fit_transform(Jung['identified'])\n",
    "Jung = Jung.drop(columns=['identified'])\n",
    "Jung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Jung.drop(columns=['identified_encoded'])\n",
    "Y = Jung['identified_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(797, 9)\n",
      "Explained Variance Ratio of each principal component:\n",
      "[0.49899195 0.282692   0.10894243 0.05868484 0.02262672 0.00786886\n",
      " 0.00572934 0.00241824 0.00206183]\n"
     ]
    }
   ],
   "source": [
    "normalizer = Normalizer(norm='max')\n",
    "data_scaled = normalizer.fit_transform(X)\n",
    "pca = PCA(n_components=9)\n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "print(data_pca.shape)\n",
    "\n",
    "# Check how much variance each component explains\n",
    "print(\"Explained Variance Ratio of each principal component:\")\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 637\n",
      "Test set size: 160\n",
      "After preprocessing Training set size: (637, 9)\n",
      "After preprocessing Test set size: (160, 9)\n",
      "Class counts in Y_train: Counter({0: 350, 3: 217, 2: 31, 1: 30, 4: 9})\n",
      "Class counts in Y_test: Counter({0: 88, 3: 55, 2: 8, 1: 7, 4: 2})\n"
     ]
    }
   ],
   "source": [
    "def split_and_scale_data(X, Y, test_size=0.2, random_state=60):\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, stratify=Y, random_state=random_state)\n",
    "    \n",
    "    print(f\"Training set size: {X_train.shape[0]}\")\n",
    "    print(f\"Test set size: {X_test.shape[0]}\")\n",
    "    print(f\"After preprocessing Training set size: {X_train.shape}\")\n",
    "    print(f\"After preprocessing Test set size: {X_test.shape}\")\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, Y_train,  Y_test\n",
    "X_train_scaled,  X_test_scaled, Y_train,  Y_test = split_and_scale_data(data_pca, Y)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "class_counts = Counter(Y_train)\n",
    "print(\"Class counts in Y_train:\", class_counts)\n",
    "\n",
    "class_counts = Counter(Y_test)\n",
    "print(\"Class counts in Y_test:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = ExtraTreesClassifier(\n",
    "    n_estimators=500, max_depth=35, min_samples_split=7, min_samples_leaf=1, max_features='sqrt', random_state=42\n",
    ")\n",
    "clf2 = DecisionTreeClassifier(\n",
    "    max_depth=15, min_samples_split=14, min_samples_leaf=5, criterion='entropy', random_state=42\n",
    ")\n",
    "clf3 = SVC(\n",
    "    C=42.26721781758463, kernel='rbf', gamma='auto', probability=True, random_state=42\n",
    ")\n",
    "clf4 = xgb.XGBClassifier(\n",
    "    n_estimators=900, max_depth=9, learning_rate=0.21577743453773293,\n",
    "    subsample=0.7134596184717141, colsample_bytree=0.8926104458835206, \n",
    "    gamma=0.06934334083160099, reg_alpha=0.6613878247418032, reg_lambda=0.26856628937579974,\n",
    "    random_state=42, use_label_encoder=False, eval_metric='mlogloss'\n",
    ")\n",
    "clf5 = lgb.LGBMClassifier(\n",
    "    n_estimators=700, max_depth=7, learning_rate=0.0855852309100438, num_leaves=138, \n",
    "    min_child_samples=62, subsample=0.9673844529941501, colsample_bytree=0.7343207921501621,\n",
    "    reg_alpha=0.2369598754789148, reg_lambda=0.5701128436794478, random_state=42\n",
    ")\n",
    "clf6 = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=30, min_samples_split=4, min_samples_leaf=1, \n",
    "    max_features='log2', bootstrap=True, random_state=42\n",
    ")\n",
    "clf9 = GradientBoostingClassifier(\n",
    "    n_estimators=200, learning_rate=0.17387802436141037, max_depth=10, \n",
    "    min_samples_split=12, min_samples_leaf=6, subsample=0.547399138004244, \n",
    "    max_features='sqrt', loss='log_loss', random_state=42\n",
    ")\n",
    "clf10 = AdaBoostClassifier(\n",
    "    n_estimators=500, learning_rate=0.6574797025901895, algorithm='SAMME.R', random_state=42\n",
    ")\n",
    "clf11 = cb.CatBoostClassifier(\n",
    "    n_estimators=600, learning_rate=0.07472477144852825, max_depth=10, min_data_in_leaf=9, \n",
    "    l2_leaf_reg=7.404283846568703, border_count=192, silent=True, random_state=42\n",
    ")\n",
    "clf12 = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 128), activation='relu', solver='lbfgs', \n",
    "    alpha=0.09632315546143085, learning_rate='invscaling', max_iter=1800, random_state=42\n",
    ")\n",
    "\n",
    "# Stacking ensemble\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('et', clf1), ('dt', clf2), ('svc', clf3), ('xgb', clf4), \n",
    "        ('lgbm', clf5), ('rf', clf6), ('gb', clf9), \n",
    "        ('ab', clf10), ('catboost', clf11), ('mlp', clf12)\n",
    "    ],\n",
    "    final_estimator=ExtraTreesClassifier(\n",
    "    n_estimators=500, max_depth=35, min_samples_split=7, min_samples_leaf=1, max_features='sqrt', random_state=42\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('model', stacking_clf)  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Accuracy: 0.9500\n",
      "  F1 Score: 0.9468\n",
      "  Precision: 0.9468\n",
      "  Recall: 0.9500\n",
      "  Cohen's Kappa: 0.9121\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n",
      "  Accuracy: 0.9250\n",
      "  F1 Score: 0.9135\n",
      "  Precision: 0.9159\n",
      "  Recall: 0.9250\n",
      "  Cohen's Kappa: 0.8658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3:\n",
      "  Accuracy: 0.9375\n",
      "  F1 Score: 0.9269\n",
      "  Precision: 0.9399\n",
      "  Recall: 0.9375\n",
      "  Cohen's Kappa: 0.8883\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4:\n",
      "  Accuracy: 0.9625\n",
      "  F1 Score: 0.9519\n",
      "  Precision: 0.9649\n",
      "  Recall: 0.9625\n",
      "  Cohen's Kappa: 0.9330\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5:\n",
      "  Accuracy: 0.9375\n",
      "  F1 Score: 0.9317\n",
      "  Precision: 0.9266\n",
      "  Recall: 0.9375\n",
      "  Cohen's Kappa: 0.8902\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6:\n",
      "  Accuracy: 0.9375\n",
      "  F1 Score: 0.9301\n",
      "  Precision: 0.9282\n",
      "  Recall: 0.9375\n",
      "  Cohen's Kappa: 0.8890\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7:\n",
      "  Accuracy: 0.9125\n",
      "  F1 Score: 0.8892\n",
      "  Precision: 0.8682\n",
      "  Recall: 0.9125\n",
      "  Cohen's Kappa: 0.8437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8:\n",
      "  Accuracy: 0.8987\n",
      "  F1 Score: 0.9080\n",
      "  Precision: 0.9239\n",
      "  Recall: 0.8987\n",
      "  Cohen's Kappa: 0.8269\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9:\n",
      "  Accuracy: 0.9241\n",
      "  F1 Score: 0.9235\n",
      "  Precision: 0.9249\n",
      "  Recall: 0.9241\n",
      "  Cohen's Kappa: 0.8662\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/kumail/anaconda3/envs/AliHaq/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10:\n",
      "  Accuracy: 0.9873\n",
      "  F1 Score: 0.9862\n",
      "  Precision: 0.9878\n",
      "  Recall: 0.9873\n",
      "  Cohen's Kappa: 0.9778\n",
      "\n",
      "Overall Results:\n",
      "Mean Accuracy: 0.9373, Std Dev: 0.0239\n",
      "Mean F1 Score: 0.9308, Std Dev: 0.0253\n",
      "Mean Precision: 0.9327, Std Dev: 0.0299\n",
      "Mean Recall: 0.9373, Std Dev: 0.0239\n",
      "Mean Cohen's Kappa: 0.8893, Std Dev: 0.0416\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=60)\n",
    "\n",
    "Y = Y.to_numpy() if isinstance(Y, pd.Series) else Y\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "kappas = []\n",
    "\n",
    "fold_idx = 1\n",
    "for train_idx, test_idx in cv.split(data_pca, Y):\n",
    "    X_train, X_test = data_pca[train_idx], data_pca[test_idx]\n",
    "    y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "    \n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    y_pred = stacking_clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    kappas.append(kappa)\n",
    "\n",
    "    print(f\"Fold {fold_idx}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  Cohen's Kappa: {kappa:.4f}\\n\")\n",
    "    fold_idx += 1\n",
    "\n",
    "print(\"Overall Results:\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f}, Std Dev: {np.std(accuracies):.4f}\")\n",
    "print(f\"Mean F1 Score: {np.mean(f1_scores):.4f}, Std Dev: {np.std(f1_scores):.4f}\")\n",
    "print(f\"Mean Precision: {np.mean(precisions):.4f}, Std Dev: {np.std(precisions):.4f}\")\n",
    "print(f\"Mean Recall: {np.mean(recalls):.4f}, Std Dev: {np.std(recalls):.4f}\")\n",
    "print(f\"Mean Cohen's Kappa: {np.mean(kappas):.4f}, Std Dev: {np.std(kappas):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AliHaq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
